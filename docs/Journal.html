<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>Portfolio</title>

<script src="site_libs/header-attrs-2.21/header-attrs.js"></script>
<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>









<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark the anchor link active (and if it's in a dropdown, also mark that active)
  var dropdown = menuAnchor.closest('li.dropdown');
  if (window.bootstrap) { // Bootstrap 4+
    menuAnchor.addClass('active');
    dropdown.find('> .dropdown-toggle').addClass('active');
  } else { // Bootstrap 3
    menuAnchor.parent().addClass('active');
    dropdown.addClass('active');
  }

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before, .tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "\e259";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "\e258";
  font-family: 'Glyphicons Halflings';
  border: none;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-bs-toggle="collapse" data-target="#navbar" data-bs-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">MyLabJournal</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li>
  <a href="Journal.html">Journal</a>
</li>
<li>
  <a href="Links.html">Links</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">



<h1 class="title toc-ignore">Portfolio</h1>

</div>


<div id="coursework" class="section level1">
<h1>Coursework</h1>
<div id="sta4241-statistical-learning" class="section level2">
<h2>STA4241: Statistical Learning</h2>
<div id="spring-2022" class="section level3">
<h3>Spring 2022</h3>
<div id="homework-1" class="section level4">
<h4>Homework #1</h4>
<p><strong>Question 1</strong></p>
<p>To find the least squares solution for <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span> in simple linear regression, we must minimize the sum of squared residuals for <span class="math inline">\(Y=\beta_0+\beta_1X\)</span> by minimizing <span class="math inline">\(\sum_{i=1}^n(Y_i-(\hat{\beta}_0+\hat{\beta}_1X_i))^2\)</span>. To begin, we will minimize the function with respect to <span class="math inline">\(\hat{\beta}_0\)</span>: <span class="math display">\[\frac{\partial}{\partial\hat{\beta}_0}\sum_{i=1}^n(Y_i-(\hat{\beta}_0+\hat{\beta}_1X_i))^2=\sum_{i=1}^n\frac{\partial}{\partial\hat{\beta}_0}(Y_i-(\hat{\beta}_0+\hat{\beta}_1X_i))^2\]</span> <span class="math display">\[=\sum_{i=1}^n2(Y_i-(\hat{\beta}_0+\hat{\beta}_1X_i))(-1)=-2\sum_{i=1}^n(Y_i-(\hat{\beta}_0+\hat{\beta}_1X_i))\]</span> Next, we will solve for <span class="math inline">\(\hat{\beta}_0\)</span> when the derivative equals 0: <span class="math display">\[-2\sum_{i=1}^n(Y_i-(\hat{\beta}_0+\hat{\beta}_1X_i))=0\Rightarrow\sum_{i=1}^n(Y_i-(\hat{\beta}_0+\hat{\beta}_1X_i))=0\]</span> <span class="math display">\[=\sum_{i=1}^nY_i-\sum_{i=1}^n\hat{\beta}_0-\sum_{i=1}^n\hat{\beta}_1X_i=\sum_{i=1}^nY_i-n\hat{\beta}_0-\hat{\beta}_1\sum_{i=1}^nX_i=0\]</span> <span class="math display">\[n\hat{\beta}_0=\sum_{i=1}^nY_i-\hat{\beta}_1\sum_{i=1}^nX_i\]</span> <span class="math display">\[\hat{\beta}_0=\bar{Y}-\hat{\beta}_1\bar{X}\]</span> Thus, the least squares solution for <span class="math inline">\(\beta_0\)</span> is <span class="math inline">\(\hat{\beta}_0=\bar{Y}-\hat{\beta}_1\bar{X}\)</span>. Next, we will minimize <span class="math inline">\(\sum_{i=1}^n(Y_i-(\hat{\beta}_0+\hat{\beta}_1X_i))^2\)</span> with respect to <span class="math inline">\(\hat{\beta}_1\)</span>: <span class="math display">\[\frac{\partial}{\partial\hat{\beta}_1}\sum_{i=1}^n(Y_i-(\hat{\beta}_0+\hat{\beta}_1X_i))^2=\sum_{i=1}^n\frac{\partial}{\partial\hat{\beta}_1}(Y_i-(\hat{\beta}_0+\hat{\beta}_1X_i))^2\]</span> <span class="math display">\[=\sum_{i=1}^n2(Y_i-(\hat{\beta}_0+\hat{\beta}_1X_i))(-X_i)=-2\sum_{i=1}^nX_i(Y_i-(\hat{\beta}_0+\hat{\beta}_1X_i))\]</span> Next, we will solve for <span class="math inline">\(\hat{\beta}_1\)</span> when the derivative equals 0: <span class="math display">\[-2\sum_{i=1}^nX_i(Y_i-(\hat{\beta}_0+\hat{\beta}_1X_i))=0\Rightarrow\sum_{i=1}^nX_i(Y_i-(\hat{\beta}_0+\hat{\beta}_1X_i))=0\]</span> Since we know that <span class="math inline">\(\hat{\beta}_0=\bar{Y}-\hat{\beta}_1\bar{X}\)</span>, we can substitute it into the above equation and get <span class="math display">\[\sum_{i=1}^nX_i(Y_i-(\bar{Y}-\hat{\beta}_1\bar{X}+\hat{\beta}_1X_i))=\sum_{i=1}^nX_i(Y_i-\bar{Y}-\hat{\beta}_1(X_i-\bar{X}))\]</span> <span class="math display">\[=\sum_{i=1}^nX_i(Y_i-\bar{Y})-\sum_{i=1}^n\hat{\beta}_1X_i(X_i-\bar{X})=0\]</span> <span class="math display">\[\sum_{i=1}^nX_i(Y_i-\bar{Y})=\hat{\beta}_1\sum_{i=1}^nX_i(X_i-\bar{X})\Rightarrow\hat{\beta}_1=\frac{\sum_{i=1}^nX_i(Y_i-\bar{Y})}{\sum_{i=1}^nX_i(X_i-\bar{X})}\]</span> <span class="math display">\[\hat{\beta}_1=\frac{\sum_{i=1}^n(X_i-\bar{X})(Y_i-\bar{Y})}{\sum_{i=1}^n(X_i-\bar{X})^2}\]</span> Thus, the least squares solution for <span class="math inline">\(\beta_1\)</span> is <span class="math inline">\(\hat{\beta}_1=\frac{\sum_{i=1}^n(X_i-\bar{X})(Y_i-\bar{Y})}{\sum_{i=1}^n(X_i-\bar{X})^2}\)</span>.</p>
<p><strong>Question 2</strong></p>
<ol style="list-style-type: lower-roman">
<li><p>If we use the Bayes classifier using the known probability above, we expect the error rates to be similar between the training and test data sets because they follow the same distribution.</p></li>
<li><p>The error rate for the training data is</p></li>
</ol>
<pre class="r"><code>yhat_train = as.numeric(pnorm(0.5*x1[1:500] - 0.4*x2[1:500]) &gt;= 0.5)
mean(y[1:500] != yhat_train)</code></pre>
<pre><code>## [1] 0.328</code></pre>
<p>The error rate for the testing data is</p>
<pre class="r"><code>yhat_test = as.numeric(pnorm(0.5*x1[501:1000] - 0.4*x2[501:1000]) &gt;= 0.5)
mean(y[501:1000] != yhat_test)</code></pre>
<pre><code>## [1] 0.312</code></pre>
<ol start="3" style="list-style-type: lower-roman">
<li>The test error rate when using KNN with <span class="math inline">\(k = 3\)</span> to classify the outcomes in the test data set is</li>
</ol>
<pre class="r"><code>knnTrain = cbind(x1[1:500], x2[1:500])
knnTest = cbind(x1[501:1000], x2[501:1000])
knnMod = knn(train=knnTrain, test=knnTest, k=3, cl=y[1:500])
knnPred = as.numeric(knnMod) - 1
mean(knnPred != y[501:1000])</code></pre>
<pre><code>## [1] 0.386</code></pre>
<ol start="4" style="list-style-type: lower-roman">
<li><p>Given the test error rate in part (iii) and the error rates found in part (ii), I do not think <span class="math inline">\(k=3\)</span> is the best choice of <span class="math inline">\(k\)</span> because it has a greater error rate than the Bayes classifier.</p></li>
<li><p>The plot showing the test error rate as a function of <span class="math inline">\(k\)</span> is below.</p></li>
</ol>
<pre class="r"><code>error_vals = 0
for (k_val in 1:50) {
  knnMod = knn(train=knnTrain, test=knnTest, k=k_val, cl=y[1:500])
  knnPred = as.numeric(knnMod) - 1
  error_vals[k_val] = mean(knnPred != y[501:1000])
}
knn_errors = data.frame(x = c(1:50), y = error_vals)
ggplot(data=knn_errors, aes(x=x, y=y)) + geom_line()+ geom_point() + 
       labs(x = &quot;K-value&quot;, y = &quot;Error Rate&quot;)</code></pre>
<p><img src="Journal_files/figure-html/question%202%20part%20v-1.png" width="384" /></p>
<p>I think the best choice of <span class="math inline">\(k\)</span> is likely between 35 and 45 because this is where the error rate stabilizes at around 0.32.</p>
<ol start="6" style="list-style-type: lower-roman">
<li><p>I believe that KNN does a good job at approximating the Bayes classifier in this data set because the error rate falls between about 0.45 and 0.32, which is close to what the error rate is for the testing data using the Bayes classifier.</p></li>
<li><p>The test error rate when we include the additional 20 covariates and use KNN with <span class="math inline">\(k=40\)</span> is:</p></li>
</ol>
<pre class="r"><code>knnTrain = cbind(x1[1:500], x2[1:500], xrandom[1:500])
knnTest = cbind(x1[501:1000], x2[501:1000], xrandom[501:1000])
knnMod = knn(train = knnTrain, test = knnTest, k = 40, cl = y[1:500])
knnPred = as.numeric(knnMod) - 1
mean(knnPred != y[501:1000])</code></pre>
<pre><code>## [1] 0.344</code></pre>
<ol start="8" style="list-style-type: lower-roman">
<li>The previous part tells us that including extraneous predictors in our model causes the KNN algorithm to perform worse. The error rate is higher when we include the additional 20 random predictors.</li>
</ol>
<p><strong>Question 3</strong></p>
<ol style="list-style-type: lower-alpha">
<li>The linear regression model that aims to predict Today using lags 1-5, Year, and Volume:</li>
</ol>
<pre class="r"><code>mod = lm(Today ~ Lag1 + Lag2 + Lag3 + Lag4 + Lag5 + factor(Year) + Volume, data = Smarket)</code></pre>
<ol style="list-style-type: lower-roman">
<li><p>I included Year as a categorical variable in my model because there are only 5 levels (years 2001-2005). R would read it as a continuous variable had I not done this, which would affect my estimates.</p></li>
<li><p>The model summary is below.</p></li>
</ol>
<pre class="r"><code>summary(mod)</code></pre>
<pre><code>## 
## Call:
## lm(formula = Today ~ Lag1 + Lag2 + Lag3 + Lag4 + Lag5 + factor(Year) + 
##     Volume, data = Smarket)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -4.9039 -0.6494  0.0187  0.5866  5.6225 
## 
## Coefficients:
##                   Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept)      -0.101032   0.161837  -0.624    0.533
## Lag1             -0.031093   0.028416  -1.094    0.274
## Lag2             -0.014610   0.028464  -0.513    0.608
## Lag3             -0.007029   0.028407  -0.247    0.805
## Lag4             -0.011074   0.028422  -0.390    0.697
## Lag5             -0.038052   0.028127  -1.353    0.176
## factor(Year)2002 -0.063032   0.105082  -0.600    0.549
## factor(Year)2003  0.148313   0.104582   1.418    0.156
## factor(Year)2004  0.079240   0.105248   0.753    0.452
## factor(Year)2005  0.032578   0.131108   0.248    0.804
## Volume            0.043872   0.117897   0.372    0.710
## 
## Residual standard error: 1.137 on 1239 degrees of freedom
## Multiple R-squared:  0.006222,   Adjusted R-squared:  -0.001799 
## F-statistic: 0.7757 on 10 and 1239 DF,  p-value: 0.6525</code></pre>
<p>The test statistic is <span class="math inline">\(F=0.7757\)</span>. The p-value of obtaining this test statistic with <span class="math inline">\(df_1=10\)</span>, <span class="math inline">\(df_2=1239\)</span> is <span class="math inline">\(0.6525\)</span>. Because this p-value is greater than all common alpha levels, I fail to reject the null hypothesis that <span class="math inline">\(\beta_1=...=\beta_{10}=0\)</span>.</p>
<ol start="3" style="list-style-type: lower-roman">
<li>The model with the same covariates and including lag 1 in the model with a three degree of freedom polynomial is:</li>
</ol>
<pre class="r"><code>lag1mod = lm(Today ~ poly(Lag1, 3) + Lag2 + Lag3 + Lag4 + Lag5 + factor(Year) + Volume, 
             data = Smarket)
summary(lag1mod)</code></pre>
<pre><code>## 
## Call:
## lm(formula = Today ~ poly(Lag1, 3) + Lag2 + Lag3 + Lag4 + Lag5 + 
##     factor(Year) + Volume, data = Smarket)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -4.9054 -0.6410  0.0183  0.5853  5.6312 
## 
## Coefficients:
##                   Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept)      -0.105622   0.165598  -0.638    0.524
## poly(Lag1, 3)1   -1.249910   1.142025  -1.094    0.274
## poly(Lag1, 3)2   -0.142793   1.259568  -0.113    0.910
## poly(Lag1, 3)3    0.341677   1.145983   0.298    0.766
## Lag2             -0.015232   0.028572  -0.533    0.594
## Lag3             -0.007392   0.028589  -0.259    0.796
## Lag4             -0.011426   0.028474  -0.401    0.688
## Lag5             -0.037783   0.028208  -1.339    0.181
## factor(Year)2002 -0.063926   0.105490  -0.606    0.545
## factor(Year)2003  0.146177   0.105390   1.387    0.166
## factor(Year)2004  0.075023   0.107842   0.696    0.487
## factor(Year)2005  0.025512   0.137310   0.186    0.853
## Volume            0.048849   0.122472   0.399    0.690
## 
## Residual standard error: 1.138 on 1237 degrees of freedom
## Multiple R-squared:  0.006302,   Adjusted R-squared:  -0.003337 
## F-statistic: 0.6538 on 12 and 1237 DF,  p-value: 0.7966</code></pre>
<p>The model <strong>does not</strong> fit better than the model that includes lag 1 linearly. With a test statistic of <span class="math inline">\(F=0.6538\)</span> and p-value <span class="math inline">\(0.7966\)</span>, we would again fail to reject the null hypothesis that none of the predictors are significant.</p>
<ol start="2" style="list-style-type: lower-alpha">
<li></li>
<li>The smallest test set error I could achieve was around <span class="math inline">\(0.47\)</span>.</li>
</ol>
<pre class="r"><code>set.seed(123)
sample = sample(seq_len(nrow(Smarket)), size = 625)
training = Smarket[sample,]
testing = Smarket[-sample,]
knnMarket = knn(train=training[,1:7], test=testing[,1:7], k=42, cl=training$Direction)
mean(knnMarket != testing$Direction)</code></pre>
<pre><code>## [1] 0.4752</code></pre>
<ol start="2" style="list-style-type: lower-roman">
<li>The test above tells me that our covariates are not very predictive of the outcome. We are performing about as well as we would be if we were flipping a coin to decide if the market went up or down.</li>
</ol>
<p><strong>Question 4</strong></p>
<ol style="list-style-type: lower-roman">
<li><p>No, these two confidence intervals are not the same. The confidence interval for the randomly chosen individual with <span class="math inline">\(X=x_0\)</span> will be wider than the confidence interval for the average value of the outcome among subjects with <span class="math inline">\(X=x_0\)</span>. This is due to the irreducible error <span class="math inline">\(\epsilon\)</span> that we have when predicting the outcome for an individual.</p></li>
<li><p>Yes, the widths of both confidence intervals go 0 as <span class="math inline">\(n\rightarrow\infty\)</span> since <span class="math inline">\(n\)</span> is in the denominator of both margins of error. As <span class="math inline">\(n\)</span> increases, the intervals will eventually become single numbers (the estimates of the average and the randomly chosen individual) and the margin of error approaches 0.</p></li>
</ol>
</div>
</div>
<div id="third-level-header" class="section level3">
<h3>third level header</h3>
<p>Here’s an even lower level header</p>
</div>
</div>
</div>
<div id="my-second-post-note-the-order" class="section level1">
<h1>My second post (note the order)</h1>
<p>2018 | 7 | 23 Last compiled: 2023-04-12</p>
<p>I’m writing this tutorial going from the top down. And, this is how it will be printed. So, notice the second post is second in the list. If you want your most recent post to be at the top, then make a new post starting at the top. If you want the oldest first, do, then keep adding to the bottom</p>
</div>
<div id="adding-r-stuff" class="section level1">
<h1>Adding R stuff</h1>
<p>So far this is just a blog where you can write in plain text and serve your writing to a webpage. One of the main purposes of this lab journal is to record your progress learning R. The reason I am asking you to use this process is because you can both make a website, and a lab journal, and learn R all in R-studio. This makes everything really convenient and in the sam place.</p>
<p>So, let’s say you are learning how to make a histogram in R. For example, maybe you want to sample 100 numbers from a normal distribution with mean = 0, and standard deviation =1, and then you want to plot a histogram. You can do this right here by using an r code block, like this:</p>
<pre class="r"><code>samples &lt;- rnorm(100, mean=0, sd=1)
hist(samples)</code></pre>
<p><img src="Journal_files/figure-html/unnamed-chunk-1-1.png" width="672" /></p>
<p>When you knit this R Markdown document, you will see that the histogram is printed to the page, along with the R code. This document can be set up to hide the R code in the webpage, just delete the comment (hashtag), from the cold folding option in the yaml header up top. For purposes of letting yourself see the code, and me see the code, best to keep it the way that it is. You learn all of these things and more can be customized in each R code block.</p>
</div>
<div id="the-big-idea" class="section level1">
<h1>The big idea</h1>
<p>Use this lab journal to record what you do in R. This way I will be able to see what you are doing and help you along the way. You will also be creating a repository of all the things you do. You can make posts about everything. Learning specific things in R (project unrelated), and doing things for the project that we will discuss at the beginning of the Fall semester. You can get started now by fiddling around with googling things, and trying stuff out in R. I’ve placed some helpful starting links in the links page on this website</p>
</div>
<div id="what-can-you-do-right-now-by-yourself" class="section level1">
<h1>What can you do right now by yourself?</h1>
<p>It’s hard to learn programming when you don’t have specific problems that you are trying to solve. Everything just seems abstract.</p>
<p>I wrote an <a href="https://crumplab.github.io/programmingforpsych/">introductory programming book that introduces R</a>, and gives some <a href="https://crumplab.github.io/programmingforpsych/programming-challenges-i-learning-the-fundamentals.html">concrete problems for you to solve</a>.</p>
<p>To get the hang of journaling and solving the problems to learn programming, my suggestion is that you use this .Rmd file to solve the problems. It would look like this:</p>
</div>
<div id="problem-1" class="section level1">
<h1>Problem 1</h1>
<p>Do simple math with numbers, addition, subtraction, multiplication, division</p>
<pre class="r"><code>1+2</code></pre>
<pre><code>## [1] 3</code></pre>
<pre class="r"><code>2*5</code></pre>
<pre><code>## [1] 10</code></pre>
<pre class="r"><code>5/3</code></pre>
<pre><code>## [1] 1.666667</code></pre>
<pre class="r"><code>(1+6+4)/5</code></pre>
<pre><code>## [1] 2.2</code></pre>
</div>
<div id="problem-2" class="section level1">
<h1>Problem 2</h1>
<p>Put numbers into variables, do simple math on the variables</p>
<pre class="r"><code>a&lt;-1
b&lt;-2
a+b</code></pre>
<pre><code>## [1] 3</code></pre>
<pre class="r"><code>d&lt;-c(1,2,3)
e&lt;-c(5,6,7)
d+e</code></pre>
<pre><code>## [1]  6  8 10</code></pre>
<pre class="r"><code>d*e</code></pre>
<pre><code>## [1]  5 12 21</code></pre>
<pre class="r"><code>d/e</code></pre>
<pre><code>## [1] 0.2000000 0.3333333 0.4285714</code></pre>
</div>
<div id="problem-3" class="section level1">
<h1>Problem 3</h1>
<p>Write code that will place the numbers 1 to 100 separately into a variable using for loop. Then, again using the seq function.</p>
<pre class="r"><code># for loop solution
# i becomes the number 1 to 100 at each step of the loop


a &lt;- length(100) # make empty variable, set length to 100
for (i in 1:100){
  a[i] &lt;-i #assigns the number in i, to the ith index of a
}

print(a)</code></pre>
<pre><code>##   [1]   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18
##  [19]  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36
##  [37]  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54
##  [55]  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72
##  [73]  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90
##  [91]  91  92  93  94  95  96  97  98  99 100</code></pre>
<pre class="r"><code># for loop solution #2

a&lt;-c() #create empty variable using combine command
for (i in 1:100){
  a&lt;-c(a,i) # keeps combining a with itself and the new number in i
}
print(a)</code></pre>
<pre><code>##   [1]   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18
##  [19]  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36
##  [37]  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54
##  [55]  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72
##  [73]  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90
##  [91]  91  92  93  94  95  96  97  98  99 100</code></pre>
<pre class="r"><code># seq solution
a &lt;- seq(1,100,1) # look up help for seq using ?seq() in console
print(a)</code></pre>
<pre><code>##   [1]   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18
##  [19]  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36
##  [37]  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54
##  [55]  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72
##  [73]  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90
##  [91]  91  92  93  94  95  96  97  98  99 100</code></pre>
</div>
<div id="replace-this-with-problem-4" class="section level1">
<h1>Replace this with problem 4</h1>
<p>And keep going. Try to solve the problems with different scripts that provide the same solution. Good luck, Happy coding.</p>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // temporarily add toc-ignore selector to headers for the consistency with Pandoc
    $('.unlisted.unnumbered').addClass('toc-ignore')

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
