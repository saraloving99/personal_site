<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>Portfolio</title>

<script src="site_libs/header-attrs-2.21/header-attrs.js"></script>
<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>









<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark the anchor link active (and if it's in a dropdown, also mark that active)
  var dropdown = menuAnchor.closest('li.dropdown');
  if (window.bootstrap) { // Bootstrap 4+
    menuAnchor.addClass('active');
    dropdown.find('> .dropdown-toggle').addClass('active');
  } else { // Bootstrap 3
    menuAnchor.parent().addClass('active');
    dropdown.addClass('active');
  }

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before, .tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "\e259";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "\e258";
  font-family: 'Glyphicons Halflings';
  border: none;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-bs-toggle="collapse" data-target="#navbar" data-bs-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">MyLabJournal</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li>
  <a href="Journal.html">Journal</a>
</li>
<li>
  <a href="Links.html">Links</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">



<h1 class="title toc-ignore">Portfolio</h1>

</div>


<div id="coursework" class="section level1">
<h1>Coursework</h1>
<div id="sta4241-statistical-learning-spring-2022" class="section level2">
<h2>STA4241: Statistical Learning, Spring 2022</h2>
<div id="homework-1" class="section level3">
<h3>Homework #1</h3>
<p><strong>Question 1</strong></p>
<p>To find the least squares solution for <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span> in simple linear regression, we must minimize the sum of squared residuals for <span class="math inline">\(Y=\beta_0+\beta_1X\)</span> by minimizing <span class="math inline">\(\sum_{i=1}^n(Y_i-(\hat{\beta}_0+\hat{\beta}_1X_i))^2\)</span>. To begin, we will minimize the function with respect to <span class="math inline">\(\hat{\beta}_0\)</span>: <span class="math display">\[\frac{\partial}{\partial\hat{\beta}_0}\sum_{i=1}^n(Y_i-(\hat{\beta}_0+\hat{\beta}_1X_i))^2=\sum_{i=1}^n\frac{\partial}{\partial\hat{\beta}_0}(Y_i-(\hat{\beta}_0+\hat{\beta}_1X_i))^2\]</span> <span class="math display">\[=\sum_{i=1}^n2(Y_i-(\hat{\beta}_0+\hat{\beta}_1X_i))(-1)=-2\sum_{i=1}^n(Y_i-(\hat{\beta}_0+\hat{\beta}_1X_i))\]</span> Next, we will solve for <span class="math inline">\(\hat{\beta}_0\)</span> when the derivative equals 0: <span class="math display">\[-2\sum_{i=1}^n(Y_i-(\hat{\beta}_0+\hat{\beta}_1X_i))=0\Rightarrow\sum_{i=1}^n(Y_i-(\hat{\beta}_0+\hat{\beta}_1X_i))=0\]</span> <span class="math display">\[=\sum_{i=1}^nY_i-\sum_{i=1}^n\hat{\beta}_0-\sum_{i=1}^n\hat{\beta}_1X_i=\sum_{i=1}^nY_i-n\hat{\beta}_0-\hat{\beta}_1\sum_{i=1}^nX_i=0\]</span> <span class="math display">\[n\hat{\beta}_0=\sum_{i=1}^nY_i-\hat{\beta}_1\sum_{i=1}^nX_i\]</span> <span class="math display">\[\hat{\beta}_0=\bar{Y}-\hat{\beta}_1\bar{X}\]</span> Thus, the least squares solution for <span class="math inline">\(\beta_0\)</span> is <span class="math inline">\(\hat{\beta}_0=\bar{Y}-\hat{\beta}_1\bar{X}\)</span>. Next, we will minimize <span class="math inline">\(\sum_{i=1}^n(Y_i-(\hat{\beta}_0+\hat{\beta}_1X_i))^2\)</span> with respect to <span class="math inline">\(\hat{\beta}_1\)</span>: <span class="math display">\[\frac{\partial}{\partial\hat{\beta}_1}\sum_{i=1}^n(Y_i-(\hat{\beta}_0+\hat{\beta}_1X_i))^2=\sum_{i=1}^n\frac{\partial}{\partial\hat{\beta}_1}(Y_i-(\hat{\beta}_0+\hat{\beta}_1X_i))^2\]</span> <span class="math display">\[=\sum_{i=1}^n2(Y_i-(\hat{\beta}_0+\hat{\beta}_1X_i))(-X_i)=-2\sum_{i=1}^nX_i(Y_i-(\hat{\beta}_0+\hat{\beta}_1X_i))\]</span> Next, we will solve for <span class="math inline">\(\hat{\beta}_1\)</span> when the derivative equals 0: <span class="math display">\[-2\sum_{i=1}^nX_i(Y_i-(\hat{\beta}_0+\hat{\beta}_1X_i))=0\Rightarrow\sum_{i=1}^nX_i(Y_i-(\hat{\beta}_0+\hat{\beta}_1X_i))=0\]</span> Since we know that <span class="math inline">\(\hat{\beta}_0=\bar{Y}-\hat{\beta}_1\bar{X}\)</span>, we can substitute it into the above equation and get <span class="math display">\[\sum_{i=1}^nX_i(Y_i-(\bar{Y}-\hat{\beta}_1\bar{X}+\hat{\beta}_1X_i))=\sum_{i=1}^nX_i(Y_i-\bar{Y}-\hat{\beta}_1(X_i-\bar{X}))\]</span> <span class="math display">\[=\sum_{i=1}^nX_i(Y_i-\bar{Y})-\sum_{i=1}^n\hat{\beta}_1X_i(X_i-\bar{X})=0\]</span> <span class="math display">\[\sum_{i=1}^nX_i(Y_i-\bar{Y})=\hat{\beta}_1\sum_{i=1}^nX_i(X_i-\bar{X})\Rightarrow\hat{\beta}_1=\frac{\sum_{i=1}^nX_i(Y_i-\bar{Y})}{\sum_{i=1}^nX_i(X_i-\bar{X})}\]</span> <span class="math display">\[\hat{\beta}_1=\frac{\sum_{i=1}^n(X_i-\bar{X})(Y_i-\bar{Y})}{\sum_{i=1}^n(X_i-\bar{X})^2}\]</span> Thus, the least squares solution for <span class="math inline">\(\beta_1\)</span> is <span class="math inline">\(\hat{\beta}_1=\frac{\sum_{i=1}^n(X_i-\bar{X})(Y_i-\bar{Y})}{\sum_{i=1}^n(X_i-\bar{X})^2}\)</span>.</p>
<p><strong>Question 2</strong></p>
<ol style="list-style-type: lower-roman">
<li><p>If we use the Bayes classifier using the known probability above, we expect the error rates to be similar between the training and test data sets because they follow the same distribution.</p></li>
<li><p>The error rate for the training data is</p></li>
</ol>
<pre class="r"><code>yhat_train = as.numeric(pnorm(0.5*x1[1:500] - 0.4*x2[1:500]) &gt;= 0.5)
mean(y[1:500] != yhat_train)</code></pre>
<pre><code>## [1] 0.328</code></pre>
<p>The error rate for the testing data is</p>
<pre class="r"><code>yhat_test = as.numeric(pnorm(0.5*x1[501:1000] - 0.4*x2[501:1000]) &gt;= 0.5)
mean(y[501:1000] != yhat_test)</code></pre>
<pre><code>## [1] 0.312</code></pre>
<ol start="3" style="list-style-type: lower-roman">
<li>The test error rate when using KNN with <span class="math inline">\(k = 3\)</span> to classify the outcomes in the test data set is</li>
</ol>
<pre class="r"><code>knnTrain = cbind(x1[1:500], x2[1:500])
knnTest = cbind(x1[501:1000], x2[501:1000])
knnMod = knn(train=knnTrain, test=knnTest, k=3, cl=y[1:500])
knnPred = as.numeric(knnMod) - 1
mean(knnPred != y[501:1000])</code></pre>
<pre><code>## [1] 0.386</code></pre>
<ol start="4" style="list-style-type: lower-roman">
<li><p>Given the test error rate in part (iii) and the error rates found in part (ii), I do not think <span class="math inline">\(k=3\)</span> is the best choice of <span class="math inline">\(k\)</span> because it has a greater error rate than the Bayes classifier.</p></li>
<li><p>The plot showing the test error rate as a function of <span class="math inline">\(k\)</span> is below.</p></li>
</ol>
<pre class="r"><code>error_vals = 0
for (k_val in 1:50) {
  knnMod = knn(train=knnTrain, test=knnTest, k=k_val, cl=y[1:500])
  knnPred = as.numeric(knnMod) - 1
  error_vals[k_val] = mean(knnPred != y[501:1000])
}
knn_errors = data.frame(x = c(1:50), y = error_vals)
ggplot(data=knn_errors, aes(x=x, y=y)) + geom_line()+ geom_point() + 
       labs(x = &quot;K-value&quot;, y = &quot;Error Rate&quot;)</code></pre>
<p><img src="Journal_files/figure-html/question%202%20part%20v-1.png" width="384" /></p>
<p>I think the best choice of <span class="math inline">\(k\)</span> is likely between 35 and 45 because this is where the error rate stabilizes at around 0.32.</p>
<ol start="6" style="list-style-type: lower-roman">
<li><p>I believe that KNN does a good job at approximating the Bayes classifier in this data set because the error rate falls between about 0.45 and 0.32, which is close to what the error rate is for the testing data using the Bayes classifier.</p></li>
<li><p>The test error rate when we include the additional 20 covariates and use KNN with <span class="math inline">\(k=40\)</span> is:</p></li>
</ol>
<pre class="r"><code>knnTrain = cbind(x1[1:500], x2[1:500], xrandom[1:500])
knnTest = cbind(x1[501:1000], x2[501:1000], xrandom[501:1000])
knnMod = knn(train = knnTrain, test = knnTest, k = 40, cl = y[1:500])
knnPred = as.numeric(knnMod) - 1
mean(knnPred != y[501:1000])</code></pre>
<pre><code>## [1] 0.344</code></pre>
<ol start="8" style="list-style-type: lower-roman">
<li>The previous part tells us that including extraneous predictors in our model causes the KNN algorithm to perform worse. The error rate is higher when we include the additional 20 random predictors.</li>
</ol>
<p><strong>Question 3</strong></p>
<ol style="list-style-type: lower-alpha">
<li>The linear regression model that aims to predict Today using lags 1-5, Year, and Volume:</li>
</ol>
<pre class="r"><code>mod = lm(Today ~ Lag1 + Lag2 + Lag3 + Lag4 + Lag5 + factor(Year) + Volume, data = Smarket)</code></pre>
<ol style="list-style-type: lower-roman">
<li><p>I included Year as a categorical variable in my model because there are only 5 levels (years 2001-2005). R would read it as a continuous variable had I not done this, which would affect my estimates.</p></li>
<li><p>The model summary is below.</p></li>
</ol>
<pre class="r"><code>summary(mod)</code></pre>
<pre><code>## 
## Call:
## lm(formula = Today ~ Lag1 + Lag2 + Lag3 + Lag4 + Lag5 + factor(Year) + 
##     Volume, data = Smarket)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -4.9039 -0.6494  0.0187  0.5866  5.6225 
## 
## Coefficients:
##                   Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept)      -0.101032   0.161837  -0.624    0.533
## Lag1             -0.031093   0.028416  -1.094    0.274
## Lag2             -0.014610   0.028464  -0.513    0.608
## Lag3             -0.007029   0.028407  -0.247    0.805
## Lag4             -0.011074   0.028422  -0.390    0.697
## Lag5             -0.038052   0.028127  -1.353    0.176
## factor(Year)2002 -0.063032   0.105082  -0.600    0.549
## factor(Year)2003  0.148313   0.104582   1.418    0.156
## factor(Year)2004  0.079240   0.105248   0.753    0.452
## factor(Year)2005  0.032578   0.131108   0.248    0.804
## Volume            0.043872   0.117897   0.372    0.710
## 
## Residual standard error: 1.137 on 1239 degrees of freedom
## Multiple R-squared:  0.006222,   Adjusted R-squared:  -0.001799 
## F-statistic: 0.7757 on 10 and 1239 DF,  p-value: 0.6525</code></pre>
<p>The test statistic is <span class="math inline">\(F=0.7757\)</span>. The p-value of obtaining this test statistic with <span class="math inline">\(df_1=10\)</span>, <span class="math inline">\(df_2=1239\)</span> is <span class="math inline">\(0.6525\)</span>. Because this p-value is greater than all common alpha levels, I fail to reject the null hypothesis that <span class="math inline">\(\beta_1=...=\beta_{10}=0\)</span>.</p>
<ol start="3" style="list-style-type: lower-roman">
<li>The model with the same covariates and including lag 1 in the model with a three degree of freedom polynomial is:</li>
</ol>
<pre class="r"><code>lag1mod = lm(Today ~ poly(Lag1, 3) + Lag2 + Lag3 + Lag4 + Lag5 + factor(Year) + Volume, 
             data = Smarket)
summary(lag1mod)</code></pre>
<pre><code>## 
## Call:
## lm(formula = Today ~ poly(Lag1, 3) + Lag2 + Lag3 + Lag4 + Lag5 + 
##     factor(Year) + Volume, data = Smarket)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -4.9054 -0.6410  0.0183  0.5853  5.6312 
## 
## Coefficients:
##                   Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept)      -0.105622   0.165598  -0.638    0.524
## poly(Lag1, 3)1   -1.249910   1.142025  -1.094    0.274
## poly(Lag1, 3)2   -0.142793   1.259568  -0.113    0.910
## poly(Lag1, 3)3    0.341677   1.145983   0.298    0.766
## Lag2             -0.015232   0.028572  -0.533    0.594
## Lag3             -0.007392   0.028589  -0.259    0.796
## Lag4             -0.011426   0.028474  -0.401    0.688
## Lag5             -0.037783   0.028208  -1.339    0.181
## factor(Year)2002 -0.063926   0.105490  -0.606    0.545
## factor(Year)2003  0.146177   0.105390   1.387    0.166
## factor(Year)2004  0.075023   0.107842   0.696    0.487
## factor(Year)2005  0.025512   0.137310   0.186    0.853
## Volume            0.048849   0.122472   0.399    0.690
## 
## Residual standard error: 1.138 on 1237 degrees of freedom
## Multiple R-squared:  0.006302,   Adjusted R-squared:  -0.003337 
## F-statistic: 0.6538 on 12 and 1237 DF,  p-value: 0.7966</code></pre>
<p>The model <strong>does not</strong> fit better than the model that includes lag 1 linearly. With a test statistic of <span class="math inline">\(F=0.6538\)</span> and p-value <span class="math inline">\(0.7966\)</span>, we would again fail to reject the null hypothesis that none of the predictors are significant.</p>
<ol start="2" style="list-style-type: lower-alpha">
<li></li>
<li>The smallest test set error I could achieve was around <span class="math inline">\(0.47\)</span>.</li>
</ol>
<pre class="r"><code>set.seed(123)
sample = sample(seq_len(nrow(Smarket)), size = 625)
training = Smarket[sample,]
testing = Smarket[-sample,]
knnMarket = knn(train=training[,1:7], test=testing[,1:7], k=42, cl=training$Direction)
mean(knnMarket != testing$Direction)</code></pre>
<pre><code>## [1] 0.4752</code></pre>
<ol start="2" style="list-style-type: lower-roman">
<li>The test above tells me that our covariates are not very predictive of the outcome. We are performing about as well as we would be if we were flipping a coin to decide if the market went up or down.</li>
</ol>
<p><strong>Question 4</strong></p>
<ol style="list-style-type: lower-roman">
<li><p>No, these two confidence intervals are not the same. The confidence interval for the randomly chosen individual with <span class="math inline">\(X=x_0\)</span> will be wider than the confidence interval for the average value of the outcome among subjects with <span class="math inline">\(X=x_0\)</span>. This is due to the irreducible error <span class="math inline">\(\epsilon\)</span> that we have when predicting the outcome for an individual.</p></li>
<li><p>Yes, the widths of both confidence intervals go 0 as <span class="math inline">\(n\rightarrow\infty\)</span> since <span class="math inline">\(n\)</span> is in the denominator of both margins of error. As <span class="math inline">\(n\)</span> increases, the intervals will eventually become single numbers (the estimates of the average and the randomly chosen individual) and the margin of error approaches 0.</p></li>
</ol>
</div>
<div id="homework-2" class="section level3">
<h3>Homework #2</h3>
<p><strong>Question 1</strong></p>
<p>Assuming that our outcome <span class="math inline">\(Y\)</span> is binary and that we have only covariate <span class="math inline">\(x\)</span>, quadratic discriminant analysis implies a logistic regression model of the form <span class="math display">\[\log\left(\frac{P(Y=1|X=x)}{1-P(Y=1|X=x)}\right)=\log\left(\frac{P(Y=1|X=x)}{P(Y=0|X=x)}\right)\]</span> <span class="math display">\[=\log\left[\frac{\frac{\pi_1}{(2\pi)^{p/2}|\Sigma_1|^{1/2}}\exp\left(-\frac{1}{2}(x-\mu_1)^2\Sigma_1^{-1}\right)}{\sum_{K=0}^1\frac{\pi_K}{(2\pi)^{p/2}|\Sigma_K|^{1/2}}\exp\left(-\frac{1}{2}(x-\mu_K)^2\Sigma_K^{-1}\right)}\cdot\frac{\sum_{K=0}^1\frac{\pi_K}{(2\pi)^{p/2}|\Sigma_K|^{1/2}}\exp\left(-\frac{1}{2}(x-\mu_K)^2\Sigma_K^{-1}\right)}{\frac{\pi_0}{(2\pi)^{p/2}|\Sigma_0|^{1/2}}\exp\left(-\frac{1}{2}(x-\mu_0)^2\Sigma_0^{-1}\right)}\right]\]</span> <span class="math display">\[=\log\left[\frac{\frac{\pi_1}{(2\pi)^{p/2}|\Sigma_1|^{1/2}}\exp\left(-\frac{1}{2}(x-\mu_1)^2\Sigma_1^{-1}\right)}{\frac{\pi_0}{(2\pi)^{p/2}|\Sigma_0|^{1/2}}\exp\left(-\frac{1}{2}(x-\mu_0)^2\Sigma_0^{-1}\right)}\right]=\log\left[\frac{\pi_1|\Sigma_0|^{1/2}}{\pi_0|\Sigma_1|^{1/2}}\exp\left(-\frac{1}{2}\left((x-\mu_1)^2\Sigma_1^{-1}-(x-\mu_0)^2\Sigma_0^{-1}\right)\right)\right]\]</span> <span class="math display">\[=\log\left[\frac{\pi_1|\Sigma_0|^{1/2}}{\pi_0|\Sigma_1|^{1/2}}\right]-\frac{1}{2}\left((x-\mu_1)^2\Sigma_1^{-1}-(x-\mu_0)^2\Sigma_0^{-1}\right)=\log\left[\frac{\pi_1|\Sigma_0|^{1/2}}{\pi_0|\Sigma_1|^{1/2}}\right]-\frac{1}{2}\left(\frac{x^2-2x\mu_1+\mu_1^2}{\Sigma_1}-\frac{x^2-2x\mu_0+\mu_0^2}{\Sigma_0}\right)\]</span> <span class="math display">\[=\log\left[\frac{\pi_1|\Sigma_0|^{1/2}}{\pi_0|\Sigma_1|^{1/2}}\right]-\frac{1}{2}\left(\frac{x^2\Sigma_0-2x\mu_1\Sigma_0+\mu_1^2\Sigma_0-x^2\Sigma_1+2x\mu_0\Sigma_1-\mu_0^2\Sigma_1}{\Sigma_1\Sigma_0}\right)\]</span> <span class="math display">\[=\log\left[\frac{\pi_1|\Sigma_0|^{1/2}}{\pi_0|\Sigma_1|^{1/2}}\right]-\frac{1}{2\Sigma_1\Sigma_0}\left(x^2(\Sigma_0-\Sigma_1)-2x(\mu_1\Sigma_0-\mu_0\Sigma_1)+\mu_1^2\Sigma_0-\mu_0^2\Sigma_1\right)\]</span> <span class="math display">\[=\log\left[\frac{\pi_1|\Sigma_0|^{1/2}}{\pi_0|\Sigma_1|^{1/2}}\right]-\frac{\mu_1^2}{2\Sigma_1}+\frac{\mu_0^2}{2\Sigma_0}+\frac{\mu_1\Sigma_0-\mu_0\Sigma_1}{\Sigma_1\Sigma_0}x+\frac{\Sigma_1-\Sigma_0}{2\Sigma_1\Sigma_0}x^2\]</span> Thus the model is of the form <span class="math inline">\(\beta_0+\beta_1x+\beta_2\)</span> where <span class="math display">\[\beta_0=\log\left[\frac{\pi_1|\Sigma_0|^{1/2}}{\pi_0|\Sigma_1|^{1/2}}\right]-\frac{\mu_1^2}{2\Sigma_1}+\frac{\mu_0^2}{2\Sigma_0}\]</span> <span class="math display">\[\beta_1=\frac{\mu_1\Sigma_0-\mu_0\Sigma_1}{\Sigma_1\Sigma_0}\]</span> <span class="math display">\[\beta_2=\frac{\Sigma_1-\Sigma_0}{2\Sigma_1\Sigma_0}\]</span>.</p>
<p><strong>Question 2</strong></p>
<pre class="r"><code>Problem2&lt;-read.csv(&quot;/Users/saraloving/Desktop/Sara&#39;s Folder/UF Year 4/Spring 2022/STA4241/Homework 2/Data/Problem2.csv&quot;)
logit &lt;- glm(Y ~ X1 + X2, data = Problem2, family = &quot;binomial&quot;)
logitsq &lt;- glm(Y ~ poly(X1, 2) + poly(X2, 2), data = Problem2, family = &quot;binomial&quot;)
lda &lt;- lda(Y ~ X1 + X2, data = Problem2)
qda &lt;- qda(Y ~ X1 + X2, data = Problem2)</code></pre>
<ol style="list-style-type: lower-roman">
<li></li>
</ol>
<pre class="r"><code>gridX1&lt;-seq(-3, 3, length = 50)
gridX2&lt;-seq(-3, 3, length = 50)
gridX&lt;-expand.grid(gridX1, gridX2)
names(gridX)&lt;-c(&quot;X1&quot;, &quot;X2&quot;)
gridX$logitpred &lt;- as.character(1*(predict(logit, gridX, type=&quot;response&quot;) &gt; 0.5))
gridX$logitsqpred &lt;- as.character(1*(predict(logitsq, gridX, type=&quot;response&quot;) &gt; 0.5))
gridX$ldapred &lt;- as.character(as.numeric(predict(lda, newdata = gridX)$class) - 1)
gridX$qdapred &lt;- as.character(as.numeric(predict(qda, newdata = gridX)$class) - 1)
ggplot(data = gridX, aes(x = X1, y = X2, color = logitpred)) + theme_bw() + geom_point() +
     scale_colour_manual(values = c(&quot;blue&quot;, &quot;green&quot;)) +
     labs(title = &quot;Logistic regression with only linear terms&quot;, x = &quot;X1&quot;, y = &quot;X2&quot;) +
     guides(color = guide_legend())</code></pre>
<p><img src="Journal_files/figure-html/q2i-1.png" width="384" style="display: block; margin: auto;" /></p>
<pre class="r"><code>ggplot(data = gridX, aes(x = X1, y = X2, color = logitsqpred)) + theme_bw() + geom_point() +
     scale_colour_manual(values = c(&quot;blue&quot;, &quot;green&quot;)) +
     labs(title = &quot;Logistic regression with squared terms&quot;, x = &quot;X1&quot;, y = &quot;X2&quot;) +
     guides(color = guide_legend())</code></pre>
<p><img src="Journal_files/figure-html/q2i-2.png" width="384" style="display: block; margin: auto;" /></p>
<pre class="r"><code>ggplot(data = gridX, aes(x = X1, y = X2, color = ldapred)) + theme_bw() + geom_point() +
     scale_colour_manual(values = c(&quot;blue&quot;, &quot;green&quot;)) +
     labs(title = &quot;Linear discriminant analysis&quot;, x = &quot;X1&quot;, y = &quot;X2&quot;) +
     guides(color = guide_legend())</code></pre>
<p><img src="Journal_files/figure-html/q2i-3.png" width="384" style="display: block; margin: auto;" /></p>
<pre class="r"><code>ggplot(data = gridX, aes(x = X1, y = X2, color = qdapred)) + theme_bw() + geom_point() +
     scale_colour_manual(values = c(&quot;blue&quot;, &quot;green&quot;)) +
     labs(title = &quot;Quadratic discriminant analysis&quot;, x = &quot;X1&quot;, y = &quot;X2&quot;) +
     guides(color = guide_legend())</code></pre>
<p><img src="Journal_files/figure-html/q2i-4.png" width="384" style="display: block; margin: auto;" /></p>
<ol start="2" style="list-style-type: lower-roman">
<li><p>It seems as if the logistic regression with only linear terms and the linear discriminant analysis perform similarly, while the quadratic discriminant analysis and the logistic regression with squared terms classify some values in the bottom left corner as 0. Quadratic discriminant analysis also classifies some values in the upper left corner as 1. We do not have any way of knowing if the approaches are overfit to the data without knowing what the distribution of the training data looks like.</p></li>
<li></li>
</ol>
<pre class="r"><code>Problem2test&lt;-read.csv(&quot;/Users/saraloving/Desktop/Sara&#39;s Folder/UF Year 4/Spring 2022/STA4241/Homework 2/Data/Problem2test.csv&quot;)
logittest&lt;-1*(predict(logit, Problem2test, type=&quot;response&quot;) &gt; 0.5)
logittesterror&lt;-mean(logittest != Problem2test$Y)
logitsqtest&lt;-1*(predict(logitsq, Problem2test, type=&quot;response&quot;) &gt; 0.5)
logitsqtesterror&lt;-mean(logitsqtest != Problem2test$Y)
ldatest&lt;-as.numeric(predict(lda, newdata = Problem2test)$class) - 1
ldatesterror&lt;-mean(ldatest != Problem2test$Y)
qdatest&lt;-as.numeric(predict(qda, newdata = Problem2test)$class) - 1
qdatesterror&lt;-mean(qdatest != Problem2test$Y)
print(paste0(&quot;The test error rate for the logistic regression with linear terms is &quot;, 
             signif(logittesterror, digits = 3)))</code></pre>
<pre><code>## [1] &quot;The test error rate for the logistic regression with linear terms is 0.296&quot;</code></pre>
<pre class="r"><code>print(paste0(&quot;The test error rate for the logistic regression that includes squared terms is &quot;, 
             signif(logitsqtesterror, digits = 3)))</code></pre>
<pre><code>## [1] &quot;The test error rate for the logistic regression that includes squared terms is 0.307&quot;</code></pre>
<pre class="r"><code>print(paste0(&quot;The test error rate for the linear discriminant analysis is &quot;, 
             signif(ldatesterror, digits = 3)))</code></pre>
<pre><code>## [1] &quot;The test error rate for the linear discriminant analysis is 0.297&quot;</code></pre>
<pre class="r"><code>print(paste0(&quot;The test error rate for the quadratic discriminant analysis is &quot;, 
             signif(qdatesterror, digits = 3)))</code></pre>
<pre><code>## [1] &quot;The test error rate for the quadratic discriminant analysis is 0.313&quot;</code></pre>
<p>While the models perform similarly, it seems as though the logistic regression with linear terms for the covariates is the best at predicting the outcome. This model performs only slightly better than linear discriminant analysis, followed in performance by logistic regression with squared terms and then by quadratic discriminant analysis. Considering that the logistic regression model with squared terms for X1 and X2 as well as the quadratic discriminant analysis have higher test error rates, it seems as though both X1 and X2 are best included linearly in the model.</p>
<p><strong>Question 3</strong></p>
<pre class="r"><code>Problem3&lt;-read.csv(&quot;/Users/saraloving/Desktop/Sara&#39;s Folder/UF Year 4/Spring 2022/STA4241/Homework 2/Data/Problem3.csv&quot;)
ldap3 &lt;- lda(Y ~ X1 + X2, data = Problem3)
qdap3 &lt;- qda(Y ~ X1 + X2, data = Problem3)</code></pre>
<ol style="list-style-type: lower-roman">
<li></li>
</ol>
<pre class="r"><code>gridX1p3&lt;-seq(-3, 3, length = 50)
gridX2p3&lt;-seq(-3, 3, length = 50)
gridXp3&lt;-expand.grid(gridX1p3, gridX2p3)
names(gridXp3)&lt;-c(&quot;X1&quot;, &quot;X2&quot;)
gridXp3$ldapred &lt;- as.character(as.numeric(predict(ldap3, newdata = gridXp3)$class) - 1)
gridXp3$qdapred &lt;- as.character(as.numeric(predict(qdap3, newdata = gridXp3)$class) - 1)
ggplot(data = gridXp3, aes(x = X1, y = X2, color = ldapred)) + theme_bw() + geom_point() + 
  scale_colour_manual(values = c(&quot;blue&quot;, &quot;green&quot;, &quot;purple&quot;, &quot;lightblue&quot;)) + 
  labs(title = &quot;Linear discriminant analysis&quot;, x = &quot;X1&quot;, y = &quot;X2&quot;) +  
  guides(color = guide_legend())</code></pre>
<p><img src="Journal_files/figure-html/q3i-1.png" width="384" style="display: block; margin: auto;" /></p>
<pre class="r"><code>ggplot(data = gridXp3, aes(x = X1, y = X2, color = qdapred)) + theme_bw() + geom_point() + 
  scale_colour_manual(values = c(&quot;blue&quot;, &quot;green&quot;, &quot;purple&quot;, &quot;lightblue&quot;)) + 
  labs(title = &quot;Quadratic discriminant analysis&quot;, x = &quot;X1&quot;, y = &quot;X2&quot;) + 
  guides(color = guide_legend())</code></pre>
<p><img src="Journal_files/figure-html/q3i-2.png" width="384" style="display: block; margin: auto;" /></p>
<ol start="2" style="list-style-type: lower-roman">
<li></li>
</ol>
<pre class="r"><code>Problem3test&lt;-read.csv(&quot;/Users/saraloving/Desktop/Sara&#39;s Folder/UF Year 4/Spring 2022/STA4241/Homework 2/Data/Problem3test.csv&quot;)
ldap3test&lt;-as.numeric(predict(ldap3, newdata = Problem3test)$class) - 1
ldap3testerror&lt;-mean(ldap3test != Problem3test$Y)
qdap3test&lt;-as.numeric(predict(qdap3, newdata = Problem3test)$class) - 1
qdap3testerror&lt;-mean(qdap3test != Problem3test$Y)
print(paste0(&quot;The test error rate for the linear discriminant analysis is &quot;, 
             signif(ldap3testerror, digits = 3)))</code></pre>
<pre><code>## [1] &quot;The test error rate for the linear discriminant analysis is 0.56&quot;</code></pre>
<pre class="r"><code>print(paste0(&quot;The test error rate for the quadratic discriminant analysis is &quot;, 
             signif(qdap3testerror, digits = 3)))</code></pre>
<pre><code>## [1] &quot;The test error rate for the quadratic discriminant analysis is 0.595&quot;</code></pre>
<p>The test error rate is slightly lower for linear discriminant analysis compared to quadratic discriminant analysis. Both error rates are not entirely desirable, as they are both larger than <span class="math inline">\(50\%\)</span>; however, this should not concern us.</p>
<ol start="3" style="list-style-type: lower-roman">
<li><p>No, it should not concern us that our error rates are greater than <span class="math inline">\(50\%\)</span>. Because we are trying to classify <span class="math inline">\(Y\)</span> according to four categories, we should mainly be concerned if our error rates are greater than <span class="math inline">\(75\%\)</span>.</p></li>
<li><p>Yes, I do believe that our QDA model is an improvement on random guessing because the error rate, <span class="math inline">\(59.5\%\)</span>, is lower than <span class="math inline">\(75\%\)</span>, which is what we would expect the error rate to be if we randomly picked a class category with equal probability for each class.</p></li>
</ol>
<p><strong>Question 4</strong></p>
<pre class="r"><code>set.seed(123)
n &lt;- 100
n_test &lt;- 1000

data_test &lt;- data.frame(X1 = rnorm(n_test), X2 = rnorm(n_test))
data_test$Y &lt;- 1*(data_test[,1]^2 + data_test[,2]^2 &lt; 1)

nSim &lt;- 100
test_error &lt;- matrix(NA, nSim, 2)

for (ni in 1 : nSim) {
  data_train &lt;- data.frame(X1 = rnorm(n), X2 = rnorm(n))
  data_train$Y &lt;- 1*(data_train[,1]^2 + data_train[,2]^2 &lt; 1)
  
  modLDA &lt;- lda(Y ~ X1 + X2, data = data_train)
  pred_testLDA &lt;- as.numeric(predict(modLDA, newdata = data_test)$class) - 1
  test_error[ni, 1] &lt;- mean(pred_testLDA != data_test$Y)
  
  modQDA &lt;- qda(Y ~ X1 + X2, data = data_train)
  pred_testQDA &lt;- as.numeric(predict(modQDA, newdata = data_test)$class) - 1
  test_error[ni, 2] &lt;- mean(pred_testQDA != data_test$Y)
}</code></pre>
<ol style="list-style-type: lower-roman">
<li><p>I began by setting a seed so that my code will be reproducible. Next, I defined my sample sizes for my training data (n) and my testing data (n_test). Then, I created my testing data by making a data frame with random, normally-distributed covariates <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span>. Next, I defined the binary outcome <span class="math inline">\(Y\)</span> of my testing data using squared terms for <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span>. I then set the number of simulations to be <span class="math inline">\(100\)</span> and created an empty matrix to store the test error rates for my models in two columns, one for LDA and one for QDA. Finally, I created a for loop that runs <span class="math inline">\(100\)</span> simulations of creating training data with the same properties as my testing data, running LDA and QDA, and calculating the error rates for both.</p></li>
<li><p>I believe that QDA will outperform LDA in this situation because the outcome was generated according to a quadratic function of <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span>. Since the “truth” is nonlinear, QDA will outperform LDA in this situation.</p></li>
<li></li>
</ol>
<pre class="r"><code>boxplot(x = test_error, names = c(&quot;LDA&quot;, &quot;QDA&quot;), main = &quot;Test error rates&quot;)</code></pre>
<p><img src="Journal_files/figure-html/q4iii-1.png" width="384" style="display: block; margin: auto;" /></p>
<pre class="r"><code>test_error_lda &lt;- mean(test_error[,1])
test_error_qda &lt;- mean(test_error[,2])
print(paste0(&quot;The test error rate for the linear discriminant analysis is &quot;, 
             signif(test_error_lda, digits = 2)))</code></pre>
<pre><code>## [1] &quot;The test error rate for the linear discriminant analysis is 0.44&quot;</code></pre>
<pre class="r"><code>print(paste0(&quot;The test error rate for the quadratic discriminant analysis is &quot;, 
             signif(test_error_qda, digits = 2)))</code></pre>
<pre><code>## [1] &quot;The test error rate for the quadratic discriminant analysis is 0.088&quot;</code></pre>
<p>The average error rate for LDA was <span class="math inline">\(44\%\)</span> while the average error rate for QDA was <span class="math inline">\(8.8\%\)</span>. We can see from the boxplots of the error rates that QDA consistently outperforms LDA and that the error rates for LDA are somewhat skewed to the right. As we planned, QDA is a much better method than LDA for the data we’ve generated.</p>
<ol start="4" style="list-style-type: lower-roman">
<li></li>
</ol>
<pre class="r"><code>set.seed(123)

test_error_ss &lt;- matrix(NA, 100, 3)
row &lt;- 1

for(i in seq(100, 10000, by = 100)) {
  
  test_error_ss[row, 1] &lt;- i
  
  data_test &lt;- data.frame(X1 = rnorm(100), X2 = rnorm(100))
  data_test$Y &lt;- 1*(data_test[,1]^2 + data_test[,2]^2 &lt; 1)
  
  data_train &lt;- data.frame(X1 = rnorm(i), X2 = rnorm(i))
  data_train$Y &lt;- 1*(data_train[,1]^2 + data_train[,2]^2 &lt; 1)
  
  ldap4 &lt;- lda(Y ~ X1 + X2, data = data_train)
  ldap4testerror &lt;- as.numeric(predict(ldap4, newdata = data_test)$class) - 1
  test_error_ss[row, 2] &lt;- mean(ldap4testerror != data_test$Y)
  
  qdap4 &lt;- qda(Y ~ X1 + X2, data = data_train)
  qdap4testerror &lt;- as.numeric(predict(qdap4, newdata = data_test)$class) - 1
  test_error_ss[row, 3] &lt;- mean(qdap4testerror != data_test$Y)
  
  row &lt;- row + 1
}

plot(test_error_ss[,1], test_error_ss[,2], ylim = c(0, 0.6), col = &quot;purple&quot;, main = &quot;Test Error Rate vs. Sample Size&quot;, xlab = &quot;Training Sample Size&quot;, ylab = &quot;Test Error Rate&quot;)
points(test_error_ss[,1], test_error_ss[,3], col = &quot;blue&quot;)
legend(x = &quot;topright&quot;, legend = c(&quot;LDA&quot;, &quot;QDA&quot;), col = c(&quot;purple&quot;, &quot;blue&quot;), pch = c(1, 1))</code></pre>
<p><img src="Journal_files/figure-html/q4iv-1.png" width="672" /></p>
<p>It seems as though the relative performance of LDA/QDA does not really depend on the sample size. Looking at 100 sample sizes ranging from 100 to 10,000, both the error rates for LDA and for QDA are fairly randomly scattered, though those for QDA are slightly less scattered than those for LDA. Furthermore, as explained previously, the error rates for LDA are consistently higher than those for QDA.</p>
</div>
<div id="homework-3" class="section level3">
<h3>Homework #3</h3>
<p><strong>Question 1</strong></p>
<pre class="r"><code>Problem1 &lt;- read.table(&quot;/Users/saraloving/Desktop/Sara&#39;s Folder/UF Year 4/Spring 2022/STA4241/Homework 3/Crabs.dat&quot;, 
                       header = TRUE, 
                       colClasses = c(&quot;factor&quot;, rep(&quot;double&quot;, 2), rep(&quot;factor&quot;, 2)))</code></pre>
<ol style="list-style-type: lower-roman">
<li><p>Weight and width are continuous variables, while color and spine are categorical variables. Since color and spine are discrete variables, they will be included in our model as factors. This should be done for most models since these do not have a natural order. Furthermore, it alleviates some issues that could arise with using KNN algorithms, which assume that all outcomes exist in a hypothetical space in which distance can be measured. We are assuming by implementing LDA and QDA in this problem that the predictor variables follow a multivariate normal distribution; however, there has been research that supports the fact that LDA is somewhat robust against this assumption.</p></li>
<li></li>
</ol>
<pre class="r"><code>nSim &lt;- 100
errorMat &lt;- matrix(NA, nSim, 4)
trainErrorMat &lt;- matrix(NA, nSim, 4)

for (ni in 1 : nSim) {
  set.seed(ni)
  
  trainIndex &lt;- sample(1:nrow(Problem1), 100, replace = FALSE)
  
  trainData &lt;- Problem1[trainIndex,]
  testData &lt;- Problem1[-trainIndex,]
  
  tune.svm &lt;- tune(svm, y ~ .,
                   data = trainData, kernel = &quot;radial&quot;,
                   ranges = list(cost = c(0.01, 1, 5, 10, 100),
                                 gamma = c(0.01)))
  fit &lt;- tune.svm$best.model
  
  predSVM &lt;- as.numeric(as.character(predict(fit, testData)))
  trainPredSVM &lt;- as.numeric(as.character(fit$fitted))
  
  errorMat[ni, 1] &lt;- mean(predSVM != testData$y)
  trainErrorMat[ni, 1] &lt;- mean(trainPredSVM != trainData$y)
  
  tune.svm &lt;- tune(svm, y ~.,
                   data = trainData, kernel = &quot;radial&quot;,
                   ranges = list(cost = c(0.01, 1, 5, 10, 100),
                                 gamma = c(0.1)))
  fit &lt;- tune.svm$best.model
  
  predSVM &lt;- as.numeric(as.character(predict(fit, testData)))
  trainPredSVM &lt;- as.numeric(as.character(fit$fitted))
  
  errorMat[ni, 2] &lt;- mean(predSVM != testData$y)
  trainErrorMat[ni, 2] &lt;- mean(trainPredSVM != trainData$y)
  
  tune.svm &lt;- tune(svm, y ~.,
                   data = trainData, kernel = &quot;radial&quot;,
                   ranges = list(cost = c(0.01, 1, 5, 10, 100),
                                 gamma = c(1)))
  fit &lt;- tune.svm$best.model
  
  predSVM &lt;- as.numeric(as.character(predict(fit, testData)))
  trainPredSVM &lt;- as.numeric(as.character(fit$fitted))
  
  errorMat[ni, 3] &lt;- mean(predSVM != testData$y)
  trainErrorMat[ni, 3] &lt;- mean(trainPredSVM != trainData$y)
  
  tune.svm &lt;- tune(svm, y ~.,
                   data = trainData, kernel = &quot;radial&quot;,
                   ranges = list(cost = c(0.01, 1, 5, 10, 100),
                                 gamma = c(10)))
  fit &lt;- tune.svm$best.model
  
  predSVM &lt;- as.numeric(as.character(predict(fit, testData)))
  trainPredSVM &lt;- as.numeric(as.character(fit$fitted))
  
  errorMat[ni, 4] &lt;- mean(predSVM != testData$y)
  trainErrorMat[ni, 4] &lt;- mean(trainPredSVM != trainData$y)
}


trainError &lt;- apply(trainErrorMat, 2, mean, na.rm=TRUE)
testError &lt;- apply(errorMat, 2, mean, na.rm=TRUE)
table &lt;- data.frame(testing = testError, training = trainError) 
row.names(table) &lt;- c(&quot;gamma = .001&quot;, &quot;gamma = .01&quot;, &quot;gamma = 1&quot;, &quot;gamma = 10&quot;)
table</code></pre>
<pre><code>##                testing training
## gamma = .001 0.3384932   0.2669
## gamma = .01  0.3230137   0.2336
## gamma = 1    0.3476712   0.2042
## gamma = 10   0.3745205   0.2045</code></pre>
<p>I created a for loop to test four different gamma values. I first held out 100 observations to be used as training data and let the other 73 observations be the testing data. I then chose four values of gamma (<span class="math inline">\(\gamma\)</span>): 0.01, 0.1, 1, and 10, to test the sensitivity of the results. I did this 100 times and set a different seed each time to simulate randomness. From the table above, we can see that the testing error rates become larger as <span class="math inline">\(\gamma\)</span> gets larger, while the training error rates become smaller as <span class="math inline">\(\gamma\)</span> gets larger. This demonstrates that the models might be susceptible to overfitting as <span class="math inline">\(\gamma\)</span> increases.</p>
<ol start="3" style="list-style-type: lower-roman">
<li></li>
</ol>
<pre class="r"><code>set.seed(123)

errorMat &lt;- matrix(NA, 10, 6)

folds &lt;- cut(seq(1, nrow(Problem1)), breaks = 10, labels = FALSE)

for (k in 1 : 10) {
  testIndex &lt;- which(folds == k)
  
  trainData &lt;- Problem1[-testIndex,]
  testData &lt;- Problem1[testIndex,]
  
  knnTrainY &lt;- trainData$y
  knnTestY &lt;- testData$y
  
  knnTrainData &lt;- trainData
  knnTrainData$y &lt;- NULL
  
  knnTestData &lt;- testData
  knnTestData$y &lt;- NULL
  
  knnPred5 &lt;- knn(train = knnTrainData, test = knnTestData, cl = knnTrainY, k = 5) 
  knnPred10 &lt;- knn(train = knnTrainData, test = knnTestData, cl = knnTrainY, k = 10) 
  knnPred20 &lt;- knn(train = knnTrainData, test = knnTestData, cl = knnTrainY, k = 20) 
  knnPred50 &lt;- knn(train = knnTrainData, test = knnTestData, cl = knnTrainY, k = 50) 
  knnPred75 &lt;- knn(train = knnTrainData, test = knnTestData, cl = knnTrainY, k = 75) 
  knnPred100 &lt;- knn(train = knnTrainData, test = knnTestData, cl = knnTrainY, k = 100)
  
  errorMat[k, 1] &lt;- mean(knnPred5 != testData$y)   
  errorMat[k, 2] &lt;- mean(knnPred10 != testData$y) 
  errorMat[k, 3] &lt;- mean(knnPred20 != testData$y) 
  errorMat[k, 4] &lt;- mean(knnPred50 != testData$y) 
  errorMat[k, 5] &lt;- mean(knnPred75 != testData$y) 
  errorMat[k, 6] &lt;- mean(knnPred100 != testData$y)
}

errorRates &lt;- apply(errorMat, 2, mean, na.rm = TRUE)
knnTable &lt;- data.frame(&quot;error rate&quot; = errorRates) 
rownames(knnTable) &lt;- c(5, 10, 20, 50, 75, 100) 
knnTable</code></pre>
<pre><code>##     error.rate
## 5    0.2885621
## 10   0.2892157
## 20   0.3055556
## 50   0.3117647
## 75   0.3277778
## 100  0.3441176</code></pre>
<p>The optimal value of <span class="math inline">\(K\)</span> is 5 as this value gives us the lowest testing error rate at <span class="math inline">\(28.85\%\)</span>.</p>
<ol start="4" style="list-style-type: lower-roman">
<li></li>
</ol>
<pre class="r"><code>errorMat &lt;- matrix(NA, 100, 6)
colnames(errorMat) &lt;- c(&quot;Logistic Regression&quot;, &quot;LDA&quot;, &quot;QDA&quot;, &quot;KNN&quot;, &quot;SVM Poly&quot;, &quot;SVM Rad&quot;)

for (i in 1:100) {
  set.seed(i)
  
  testIndex &lt;- sample(1:nrow(Problem1), 25, replace = FALSE)
  testData &lt;- Problem1[testIndex, ]
  trainData &lt;- Problem1[-testIndex, ]
  
  fitLogistic &lt;- glm(y ~ ., data = trainData, family = &quot;binomial&quot;)
  logisticPred &lt;- 1*(predict(fitLogistic, newdata = testData, type = &quot;response&quot;) &gt; 0.5)
  errorMat[i, 1] &lt;- mean(logisticPred != testData$y)
  
  fitLDA &lt;- lda(y ~ ., data = trainData)
  ldaPred &lt;- as.numeric(predict(fitLDA, newdata = testData)$class) - 1
  errorMat[i, 2] &lt;- mean(ldaPred != testData$y)
  
  fitQDA &lt;- qda(y ~., data = trainData)
  qdaPred &lt;- as.numeric(predict(fitQDA, newdata = testData)$class) - 1
  errorMat[i, 3] &lt;- mean(qdaPred != testData$y)
  
  knn &lt;- tune.knn(x = testData[,-1], y = testData[, 1], 
                  k = c(1, 5, 10, 15, 20),
                  tunecontrol = tune.control(sampling = &quot;cross&quot;), 
                  cross = 10)
  errorMat[i, 4] &lt;- unlist(knn[[2]])
  
  tune.svm &lt;- tune(svm, y ~ ., 
                   data = trainData, kernel = &quot;polynomial&quot;, 
                   ranges = list(cost = c(0.01, 1, 5, 10, 100), degree = c(1, 2, 3, 4)))
  fitSVMPoly &lt;- tune.svm$best.model
  SVMPolyPred &lt;- as.numeric(as.character(predict(fitSVMPoly, testData)))
  errorMat[i, 5] &lt;- mean(SVMPolyPred != testData$y)
  
  tune.svm &lt;- tune(svm, y ~., 
                   data = trainData, kernel = &quot;radial&quot;, 
                   ranges = list(cost = c(0.01, 1, 5, 10, 100), 
                                 gamma = c(0.001, 0.01, 0.1, 1, 10)))
  fitSVMRad &lt;- tune.svm$best.model
  SVMRadPred &lt;- as.numeric(as.character(predict(fitSVMRad, testData)))
  errorMat[i, 6] &lt;- mean(SVMRadPred != testData$y)
}

apply(errorMat, 2, mean, na.rm = TRUE)</code></pre>
<pre><code>## Logistic Regression                 LDA                 QDA                 KNN 
##           0.3208000           0.3140000           0.3076000           0.2911667 
##            SVM Poly             SVM Rad 
##           0.3168000           0.3108000</code></pre>
<blockquote>
<ol style="list-style-type: lower-alpha">
<li>The algorithm with the best performance on average across the 100 testing data sets is KNN, since it has the lowest testing error rate.<br />
</li>
<li></li>
</ol>
</blockquote>
<pre class="r"><code>boxplot(errorMat, main = &quot;Error Rates&quot;, las = 2)</code></pre>
<p><img src="Journal_files/figure-html/h3q1ivb-1.png" width="672" /></p>
<blockquote>
<p>From the boxplots above, we can see graphically that KNN performs the best for this dataset. The averages for the rest are extremely similar. Logistic regression and LDA have the smallest ranges, but also have several outliers. The other models have similar ranges with the exception of the SVM with a polynomial kernel, whose range seems to be a bit wider.</p>
</blockquote>
<p><strong>Question 2</strong></p>
<ol style="list-style-type: lower-roman">
<li><p>Since the distribution of <span class="math inline">\(X_i\)</span> is uniform on <span class="math inline">\([0, 10]\)</span>, the value of <span class="math inline">\(q_{0.8}\)</span> is <span class="math inline">\(\frac{q_{0.8}-a}{b-a}=\frac{q_{0.8}-0}{10-0}=0.8\)</span>. Solving for <span class="math inline">\(q_{0.8}\)</span> gives us <span class="math inline">\(q_{0.8}=8\)</span>.</p></li>
<li><p>If we didn’t know the distribution of <span class="math inline">\(X_i\)</span>, we would assume that the distribution is normal since we have a large sample size (<span class="math inline">\(n = 100\)</span>). Since we know that the data fall between <span class="math inline">\([0, 10]\)</span>, and, by the Range Rule, the standard deviation of a sample is approximately equal to <span class="math inline">\(\frac{1}{4}\)</span> of the range, we can determine that the standard deviation of the distribution is around <span class="math inline">\(\frac{10}{4} = 2.5\)</span>. Thus, a good estimator for <span class="math inline">\(q_{0.8}\)</span> would satisfy <span class="math inline">\(z_{0.8} \approx 0.8416 = \frac{q_{0.8}-5}{2.5}\)</span>. Solving this provides us with <span class="math inline">\(q_{0.8} = 7.104\)</span>.</p></li>
<li></li>
</ol>
<pre class="r"><code>n &lt;- 100
set.seed(123)
x &lt;- runif(n, 0, 10)

nBoot &lt;- 1000
estBoot &lt;- rep(NA, nBoot)

for (nb in 1: nBoot) {
  sample &lt;- sample(1:n, n, replace = TRUE)
  xBoot &lt;- x[sample]
  estBoot[nb] &lt;- quantile(xBoot, 0.80)
}

mean(estBoot)</code></pre>
<pre><code>## [1] 7.942889</code></pre>
<pre class="r"><code>quantile(estBoot, c(0.025, 0.975))</code></pre>
<pre><code>##     2.5%    97.5% 
## 7.088609 8.837077</code></pre>
<ol start="4" style="list-style-type: lower-roman">
<li></li>
</ol>
<pre class="r"><code>n &lt;- 100
nSim &lt;- 200
nBoot &lt;- 1000
cov &lt;- matrix(NA, nSim, 2)
colnames(cov) &lt;- c(&quot;Percentile&quot;, &quot;Standard&quot;)
se &lt;- rep(NA, nSim)
est &lt;- rep(NA, nSim)
set.seed(123)

for (ns in 1 : nSim) {
  x &lt;- runif(n, 0, 10)
  est[ns] &lt;- quantile(x, 0.80)
  
  estBoot &lt;- rep(NA, nBoot)
  for (nb in 1 : nBoot) {
    sample &lt;- sample(1:n, n, replace = TRUE)
    xBoot &lt;- x[sample]
    estBoot[nb] &lt;- quantile(xBoot, 0.80)
  }
  
  cov[ns, 1] &lt;- 1*(quantile(estBoot, 0.025) &lt; 8 &amp; quantile(estBoot, 0.975) &gt; 8)
  se[ns] &lt;- sd(estBoot)
  cov[ns, 2] &lt;- 1*(est[ns] - 1.96*se[ns] &lt; 8 &amp; est[ns] + 1.96*se[ns] &gt; 8)
}

apply(cov, 2, mean, na.rm = TRUE)</code></pre>
<pre><code>## Percentile   Standard 
##      0.950      0.935</code></pre>
<p>The percentile method creates intervals that cover the true <span class="math inline">\(0.8\)</span> quantile <span class="math inline">\(95\%\)</span> of the time, while the standard error method covers the true parameter <span class="math inline">\(93.5\%\)</span> of the time.</p>
<ol start="22" style="list-style-type: lower-alpha">
<li></li>
</ol>
<pre class="r"><code>n &lt;- 100
nSim &lt;- 200
nBoot &lt;- 1000
cov &lt;- matrix(NA, nSim, 2)
colnames(cov) &lt;- c(&quot;Percentile&quot;, &quot;Standard&quot;)
se &lt;- rep(NA, nSim)
est &lt;- rep(NA, nSim)
set.seed(123)

for (ns in 1 : nSim) {
  x &lt;- runif(n, 0, 10)
  est[ns] &lt;- quantile(x, 0.99)
  
  estBoot &lt;- rep(NA, nBoot)
  for (nb in 1 : nBoot) {
    sample &lt;- sample(1:n, n, replace = TRUE)
    xBoot &lt;- x[sample]
    estBoot[nb] &lt;- quantile(xBoot, 0.99)
  }
  
  cov[ns, 1] &lt;- 1*(quantile(estBoot, 0.025) &lt; 9.9 &amp; quantile(estBoot, 0.975) &gt; 9.9)
  se[ns] &lt;- sd(estBoot)
  cov[ns, 2] &lt;- 1*(est[ns] - 1.96*se[ns] &lt; 9.9 &amp; est[ns] + 1.96*se[ns] &gt; 9.9)
}

apply(cov, 2, mean, na.rm = TRUE)</code></pre>
<pre><code>## Percentile   Standard 
##       0.62       0.90</code></pre>
<p>While the standard error method performs slightly worse than it did when estimating <span class="math inline">\(q_{0.8}\)</span>, the percentile method performs much worse in this case with an error rate of <span class="math inline">\(62\%\)</span>. A possible cause is that the <span class="math inline">\(0.99\)</span> quantile is extremely close to the upper limit of the distribution, so it is difficult to spread values normally about the true parameter.</p>
<p><strong>Question 3</strong></p>
<p>Let <span class="math inline">\(q_{\alpha/2}\)</span> and <span class="math inline">\(q_{1-\alpha/2}\)</span> represent the <span class="math inline">\(\alpha/2\)</span> and <span class="math inline">\(1-\alpha/2\)</span> quantiles of the bootstrap replicates <span class="math inline">\(\hat{\theta}^{(b)}\)</span>. It follows that since the distribution of <span class="math inline">\(\theta-\hat{\theta}\)</span> is approximated by <span class="math inline">\(\hat{\theta}-\hat{\theta}^{(b)}\)</span>, <span class="math display">\[1-\alpha=P(q_{\alpha/2}\leq\hat{\theta}^{(b)}\leq q_{1-\alpha/2})\]</span> <span class="math display">\[=P(-q_{\alpha/2}\geq-\hat{\theta}^{(b)}\geq -q_{1-\alpha/2})\]</span> <span class="math display">\[=P(-q_{1-\alpha/2}\leq-\hat{\theta}^{(b)}\leq -q_{\alpha/2})\]</span> <span class="math display">\[=P(\hat{\theta}-q_{1-\alpha/2}\leq\hat{\theta}-\hat{\theta}^{(b)}\leq \hat{\theta}-q_{\alpha/2})\]</span> <span class="math display">\[\approx P(\hat{\theta}-q_{1-\alpha/2}\leq\theta-\hat{\theta}\leq\hat{\theta}-q_{\alpha/2})\]</span> <span class="math display">\[=P(2\hat{\theta}-q_{1-\alpha/2}\leq\theta\leq 2\hat{\theta}-q_{\alpha/2})\]</span> Thus, <span class="math inline">\(P(2\hat{\theta}-q_{1-\alpha/2}\leq\theta\leq 2\hat{\theta}-q_{\alpha/2})\approx 1-\alpha\)</span>.</p>
</div>
</div>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // temporarily add toc-ignore selector to headers for the consistency with Pandoc
    $('.unlisted.unnumbered').addClass('toc-ignore')

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
