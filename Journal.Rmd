---
title: "Portfolio"
output:
  html_document:
    toc: true
    toc_float: true
    collapsed: false
    number_sections: false
    toc_depth: 1
    #code_folding: hide
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(message=FALSE,warning=FALSE, cache=TRUE)
library(class)
library(ggplot2)
```

# Coursework

## STA4241: Statistical Learning
### Spring 2022
#### Homework \#1

**Question 1**  

To find the least squares solution for $\beta_0$ and $\beta_1$ in simple linear regression, we must minimize the sum of squared residuals for $Y=\beta_0+\beta_1X$ by minimizing $\sum_{i=1}^n(Y_i-(\hat{\beta}_0+\hat{\beta}_1X_i))^2$. To begin, we will minimize the function with respect to $\hat{\beta}_0$: $$\frac{\partial}{\partial\hat{\beta}_0}\sum_{i=1}^n(Y_i-(\hat{\beta}_0+\hat{\beta}_1X_i))^2=\sum_{i=1}^n\frac{\partial}{\partial\hat{\beta}_0}(Y_i-(\hat{\beta}_0+\hat{\beta}_1X_i))^2$$ $$=\sum_{i=1}^n2(Y_i-(\hat{\beta}_0+\hat{\beta}_1X_i))(-1)=-2\sum_{i=1}^n(Y_i-(\hat{\beta}_0+\hat{\beta}_1X_i))$$ Next, we will solve for $\hat{\beta}_0$ when the derivative equals 0:
$$-2\sum_{i=1}^n(Y_i-(\hat{\beta}_0+\hat{\beta}_1X_i))=0\Rightarrow\sum_{i=1}^n(Y_i-(\hat{\beta}_0+\hat{\beta}_1X_i))=0$$ $$=\sum_{i=1}^nY_i-\sum_{i=1}^n\hat{\beta}_0-\sum_{i=1}^n\hat{\beta}_1X_i=\sum_{i=1}^nY_i-n\hat{\beta}_0-\hat{\beta}_1\sum_{i=1}^nX_i=0$$ $$n\hat{\beta}_0=\sum_{i=1}^nY_i-\hat{\beta}_1\sum_{i=1}^nX_i$$ $$\hat{\beta}_0=\bar{Y}-\hat{\beta}_1\bar{X}$$ Thus, the least squares solution for $\beta_0$ is $\hat{\beta}_0=\bar{Y}-\hat{\beta}_1\bar{X}$. Next, we will minimize $\sum_{i=1}^n(Y_i-(\hat{\beta}_0+\hat{\beta}_1X_i))^2$ with respect to $\hat{\beta}_1$: $$\frac{\partial}{\partial\hat{\beta}_1}\sum_{i=1}^n(Y_i-(\hat{\beta}_0+\hat{\beta}_1X_i))^2=\sum_{i=1}^n\frac{\partial}{\partial\hat{\beta}_1}(Y_i-(\hat{\beta}_0+\hat{\beta}_1X_i))^2$$ $$=\sum_{i=1}^n2(Y_i-(\hat{\beta}_0+\hat{\beta}_1X_i))(-X_i)=-2\sum_{i=1}^nX_i(Y_i-(\hat{\beta}_0+\hat{\beta}_1X_i))$$ Next, we will solve for $\hat{\beta}_1$ when the derivative equals 0: $$-2\sum_{i=1}^nX_i(Y_i-(\hat{\beta}_0+\hat{\beta}_1X_i))=0\Rightarrow\sum_{i=1}^nX_i(Y_i-(\hat{\beta}_0+\hat{\beta}_1X_i))=0$$ Since we know that $\hat{\beta}_0=\bar{Y}-\hat{\beta}_1\bar{X}$, we can substitute it into the above equation and get $$\sum_{i=1}^nX_i(Y_i-(\bar{Y}-\hat{\beta}_1\bar{X}+\hat{\beta}_1X_i))=\sum_{i=1}^nX_i(Y_i-\bar{Y}-\hat{\beta}_1(X_i-\bar{X}))$$ $$=\sum_{i=1}^nX_i(Y_i-\bar{Y})-\sum_{i=1}^n\hat{\beta}_1X_i(X_i-\bar{X})=0$$ $$\sum_{i=1}^nX_i(Y_i-\bar{Y})=\hat{\beta}_1\sum_{i=1}^nX_i(X_i-\bar{X})\Rightarrow\hat{\beta}_1=\frac{\sum_{i=1}^nX_i(Y_i-\bar{Y})}{\sum_{i=1}^nX_i(X_i-\bar{X})}$$ $$\hat{\beta}_1=\frac{\sum_{i=1}^n(X_i-\bar{X})(Y_i-\bar{Y})}{\sum_{i=1}^n(X_i-\bar{X})^2}$$ Thus, the least squares solution for $\beta_1$ is $\hat{\beta}_1=\frac{\sum_{i=1}^n(X_i-\bar{X})(Y_i-\bar{Y})}{\sum_{i=1}^n(X_i-\bar{X})^2}$.  

```{r question 2, echo = F}
load("/Users/saraloving/Desktop/Sara's Folder/UF Year 4/Spring 2022/STA4241/Homework 1/Data/Problem2.dat")
x1 = data$x1
x2 = data$x2
xrandom = data$xrandom
y = data$y
```
**Question 2**  

  (i) If we use the Bayes classifier using the known probability above, we expect the error rates to be similar between the training and test data sets because they follow the same distribution.

  (ii) The error rate for the training data is
```{r question 2 part ii train}
yhat_train = as.numeric(pnorm(0.5*x1[1:500] - 0.4*x2[1:500]) >= 0.5)
mean(y[1:500] != yhat_train)
```
  The error rate for the testing data is
```{r question 2 part ii test}
yhat_test = as.numeric(pnorm(0.5*x1[501:1000] - 0.4*x2[501:1000]) >= 0.5)
mean(y[501:1000] != yhat_test)
```

  (iii) The test error rate when using KNN with $k = 3$ to classify the outcomes in the test data set is
```{r question 2 part iii}
knnTrain = cbind(x1[1:500], x2[1:500])
knnTest = cbind(x1[501:1000], x2[501:1000])
knnMod = knn(train=knnTrain, test=knnTest, k=3, cl=y[1:500])
knnPred = as.numeric(knnMod) - 1
mean(knnPred != y[501:1000])
```
  
  (iv) Given the test error rate in part (iii) and the error rates found in part (ii), I do not think $k=3$ is the best choice of $k$ because it has a greater error rate than the Bayes classifier.
  
  (v) The plot showing the test error rate as a function of $k$ is below.  
```{r question 2 part v, fig.width = 4, fig.height = 3}
error_vals = 0
for (k_val in 1:50) {
  knnMod = knn(train=knnTrain, test=knnTest, k=k_val, cl=y[1:500])
  knnPred = as.numeric(knnMod) - 1
  error_vals[k_val] = mean(knnPred != y[501:1000])
}
knn_errors = data.frame(x = c(1:50), y = error_vals)
ggplot(data=knn_errors, aes(x=x, y=y)) + geom_line()+ geom_point() + 
       labs(x = "K-value", y = "Error Rate")
```


  I think the best choice of $k$ is likely between 35 and 45 because this is where the error rate stabilizes at around 0.32.  
  
  (vi) I believe that KNN does a good job at approximating the Bayes classifier in this data set because the error rate falls between about 0.45 and 0.32, which is close to what the error rate is for the testing data using the Bayes classifier.
  
  (vii) The test error rate when we include the additional 20 covariates and use KNN with $k=40$ is:
```{r question 2 part vii}
knnTrain = cbind(x1[1:500], x2[1:500], xrandom[1:500])
knnTest = cbind(x1[501:1000], x2[501:1000], xrandom[501:1000])
knnMod = knn(train = knnTrain, test = knnTest, k = 40, cl = y[1:500])
knnPred = as.numeric(knnMod) - 1
mean(knnPred != y[501:1000])
```

  (viii) The previous part tells us that including extraneous predictors in our model causes the KNN algorithm to perform worse. The error rate is higher when we include the additional 20 random predictors.
  
```{r question 3, echo = F}
library(ISLR)
data(Smarket)
```
**Question 3**  

  (a) The linear regression model that aims to predict Today using lags 1-5, Year, and Volume:  
  
```{r question 3 part a}
mod = lm(Today ~ Lag1 + Lag2 + Lag3 + Lag4 + Lag5 + factor(Year) + Volume, data = Smarket)
```
  
(i) I included Year as a categorical variable in my model because there are only 5 levels (years 2001-2005). R would read it as a continuous variable had I not done this, which would affect my estimates.
    
(ii) The model summary is below.  

```{r question 3 part aii}
summary(mod)
```
    
The test statistic is $F=0.7757$. The p-value of obtaining this test statistic with $df_1=10$, $df_2=1239$ is $0.6525$. Because this p-value is greater than all common alpha levels, I fail to reject the null hypothesis that $\beta_1=...=\beta_{10}=0$.  
    
(iii) The model with the same covariates and including lag 1 in the model with a three degree of freedom polynomial is:  

```{r question 3 part aiii}
lag1mod = lm(Today ~ poly(Lag1, 3) + Lag2 + Lag3 + Lag4 + Lag5 + factor(Year) + Volume, 
             data = Smarket)
summary(lag1mod)
```
  
The model **does not** fit better than the model that includes lag 1 linearly. With a test statistic of $F=0.6538$ and p-value $0.7966$, we would again fail to reject the null hypothesis that none of the predictors are significant.
  
  (b)
  
(i) The smallest test set error I could achieve was around $0.47$.  

```{r question 3 part bi}
set.seed(123)
sample = sample(seq_len(nrow(Smarket)), size = 625)
training = Smarket[sample,]
testing = Smarket[-sample,]
knnMarket = knn(train=training[,1:7], test=testing[,1:7], k=42, cl=training$Direction)
mean(knnMarket != testing$Direction)
```
    
(ii) The test above tells me that our covariates are not very predictive of the outcome. We are performing about as well as we would be if we were flipping a coin to decide if the market went up or down.
    
**Question 4**  

  (i) No, these two confidence intervals are not the same. The confidence interval for the randomly chosen individual with $X=x_0$ will be wider than the confidence interval for the average value of the outcome among subjects with $X=x_0$. This is due to the irreducible error $\epsilon$ that we have when predicting the outcome for an individual.
  
  (ii) Yes, the widths of both confidence intervals go 0 as $n\rightarrow\infty$ since $n$ is in the denominator of both margins of error. As $n$ increases, the intervals will eventually become single numbers (the estimates of the average and the randomly chosen individual) and the margin of error approaches 0.

### third level header

Here's an even lower level header

# My second post (note the order)

2018 | 7 | 23 Last compiled: `r Sys.Date()`

I'm writing this tutorial going from the top down. And, this is how it will be printed. So, notice the second post is second in the list. If you want your most recent post to be at the top, then make a new post starting at the top. If you want the oldest first, do, then keep adding to the bottom

# Adding R stuff

So far this is just a blog where you can write in plain text and serve your writing to a webpage. One of the main purposes of this lab journal is to record your progress learning R. The reason I am asking you to use this process is because you can both make a website, and a lab journal, and learn R all in R-studio. This makes everything really convenient and in the sam place. 

So, let's say you are learning how to make a histogram in R. For example, maybe you want to sample 100 numbers from a normal distribution with mean = 0, and standard deviation =1, and then you want to plot a histogram. You can do this right here by using an r code block, like this:

```{r}
samples <- rnorm(100, mean=0, sd=1)
hist(samples)
```

When you knit this R Markdown document, you will see that the histogram is printed to the page, along with the R code. This document can be set up to hide the R code in the webpage, just delete the comment (hashtag), from the cold folding option in the yaml header up top. For purposes of letting yourself see the code, and me see the code, best to keep it the way that it is. You learn all of these things and more can be customized in each R code block.

# The big idea

Use this lab journal to record what you do in R. This way I will be able to see what you are doing and help you along the way. You will also be creating a repository of all the things you do. You can make posts about everything. Learning specific things in R (project unrelated), and doing things for the project that we will discuss at the beginning of the Fall semester. You can get started now by fiddling around with googling things, and trying stuff out in R. I've placed some helpful starting links in the links page on this website

# What can you do right now by yourself?

It's hard to learn programming when you don't have specific problems that you are trying to solve. Everything just seems abstract.

I wrote an [introductory programming book that introduces R](https://crumplab.github.io/programmingforpsych/), and gives some [concrete problems for you to solve](https://crumplab.github.io/programmingforpsych/programming-challenges-i-learning-the-fundamentals.html). 

To get the hang of journaling and solving the problems to learn programming, my suggestion is that you use this .Rmd file to solve the problems. It would look like this:

# Problem 1

Do simple math with numbers, addition, subtraction, multiplication, division

```{r}
1+2
2*5
5/3
(1+6+4)/5

```

# Problem 2

Put numbers into variables, do simple math on the variables

```{r}
a<-1
b<-2
a+b

d<-c(1,2,3)
e<-c(5,6,7)
d+e
d*e
d/e

```

# Problem 3

Write code that will place the numbers 1 to 100 separately into a variable using for loop. Then, again using the seq function.

```{r}
# for loop solution
# i becomes the number 1 to 100 at each step of the loop


a <- length(100) # make empty variable, set length to 100
for (i in 1:100){
  a[i] <-i #assigns the number in i, to the ith index of a
}

print(a)

# for loop solution #2

a<-c() #create empty variable using combine command
for (i in 1:100){
  a<-c(a,i) # keeps combining a with itself and the new number in i
}
print(a)

# seq solution
a <- seq(1,100,1) # look up help for seq using ?seq() in console
print(a)

```

# Replace this with problem 4

And keep going. Try to solve the problems with different scripts that provide the same solution. Good luck, Happy coding.
